{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01e4272-d883-4019-beaa-516f5f51ccb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonode_id                   0\n",
      "sku_id                       0\n",
      "start_date                   0\n",
      "standard_capacity            0\n",
      "max_capacity                 0\n",
      "num_of_standard_prod_days    0\n",
      "num_of_max_prod_days         0\n",
      "dtype: int64\n",
      "(22230, 7)\n",
      "\n",
      "Duplicate Records:234\n",
      "(21996, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Check for Missing values\n",
    "capacity = pd.read_excel('NIU Data Visualization Competition.xlsx',sheet_name = 'capacity')\n",
    "print(capacity.isna().sum())\n",
    "print(capacity.shape)\n",
    "# Check for Duplicate records\n",
    "duplicate_count = capacity.duplicated(keep='first').sum()\n",
    "print(f\"\\nDuplicate Records:{duplicate_count}\")\n",
    "capacity=capacity.drop_duplicates()\n",
    "\n",
    "print(capacity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "faef4c2f-2772-4dc0-9071-8927a05dff8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonode_id    0\n",
      "sku_id        0\n",
      "date          0\n",
      "forecast      0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Records:0\n",
      "(56364, 4)\n"
     ]
    }
   ],
   "source": [
    "# Check for Missing values\n",
    "demand_forecast = pd.read_excel('NIU Data Visualization Competition.xlsx',sheet_name = 'demand forecast')\n",
    "print(demand_forecast.isna().sum())\n",
    "\n",
    "# Check for Duplicate records\n",
    "duplicate_count = demand_forecast.duplicated(keep='first').sum()\n",
    "print(f\"\\nDuplicate Records:{duplicate_count}\")\n",
    "\n",
    "print(demand_forecast.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e5959e2-4849-4b76-a5a9-723202488a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geonode_id    0\n",
      "org_id        0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate Records:0\n"
     ]
    }
   ],
   "source": [
    "# Check for Missing values\n",
    "org_mapping = pd.read_excel('NIU Data Visualization Competition.xlsx',sheet_name = 'supplier org mapping')\n",
    "print(org_mapping.isna().sum())\n",
    "\n",
    "# Check for Duplicate records\n",
    "duplicate_count = org_mapping.duplicated(keep='first').sum()\n",
    "print(f\"\\nDuplicate Records:{duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "442892c0-6a4b-43d1-a00c-a90ede190b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demand_fulfilled\n",
      "Ignore             32463\n",
      "Yes                14501\n",
      "Unused capacity     6005\n",
      "Not Available       4728\n",
      "No                  1412\n",
      "ignore                78\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Merge Capacity and demand forecast dataframes considering all forecast demands(Right Join)\n",
    "merged_data = pd.merge(capacity, demand_forecast, left_on=['geonode_id','sku_id','start_date'], right_on=['geonode_id','sku_id','date'],how='right')\n",
    "\n",
    "# Supplier Capacity having no forcast demand\n",
    "capacity_only = capacity.merge(demand_forecast, left_on=['geonode_id','sku_id','start_date'], right_on=['geonode_id','sku_id','date'],how = 'left',indicator = True)\n",
    "#print(capacity_only.head(2))\n",
    "capacity_not_used = capacity_only.loc[capacity_only['_merge']=='left_only']\n",
    "\n",
    "#Adding \"capacity_not_used\" rows to \"merged_data\"\n",
    "merged_data = pd.concat([merged_data,capacity_not_used])\n",
    "\n",
    "demand_fulfilled = []\n",
    "avail=[]\n",
    "\n",
    "for idx, row in merged_data.iterrows():\n",
    "    if row[\"forecast\"] <= row[\"standard_capacity\"]:\n",
    "        availability = row[\"standard_capacity\"] - row[\"forecast\"]\n",
    "    else:\n",
    "        availability = row[\"max_capacity\"] - row[\"forecast\"]\n",
    "    \n",
    "    if availability < 0:\n",
    "        demand_fulfilled.append(\"No\")    \n",
    "    elif ((availability >= 0) & (row[\"forecast\"] != 0)):\n",
    "        demand_fulfilled.append(\"Yes\")\n",
    "    elif((availability > 0) & (row[\"forecast\"] == 0))|(row[\"_merge\"] == \"left_only\"):\n",
    "        demand_fulfilled.append(\"Unused capacity\")\n",
    "    elif((availability == 0) & (row[\"forecast\"] == 0)):\n",
    "        demand_fulfilled.append(\"ignore\")    #both capacity and demand values are 0\n",
    "    elif row[\"forecast\"] != 0:\n",
    "        demand_fulfilled.append(\"Not Available\") # Capacity is not available for forecasted demand.\n",
    "    else:\n",
    "        demand_fulfilled.append(\"Ignore\")   #Capacity is not available but forecasted demand is 0.\n",
    "    \n",
    "    # Append the availability value to the avail list\n",
    "    avail.append(availability)\n",
    "\n",
    "# Add the \"avail\" and \"Demand Fullfilled\" columns to the merged_data DataFrame\n",
    "merged_data[\"avail\"] = avail\n",
    "merged_data[\"demand_fulfilled\"] = demand_fulfilled\n",
    "merged_data['month_year'] = merged_data['date'].dt.strftime('%b %y')\n",
    "\n",
    "demand_data = merged_data[\"demand_fulfilled\"].value_counts()\n",
    "print(demand_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "419be9f2-da63-45df-ba5e-9829965f50fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Function to find location for a geonode_id\n",
    "def find_location(geonode_id):\n",
    "    geolocator = Nominatim(user_agent=\"geo_locator\",timeout=100)\n",
    "    location = geolocator.geocode(geonode_id)\n",
    "    return location\n",
    "\n",
    "# Apply find_location function to each geonode_id and create a new column\n",
    "org_mapping['location'] = org_mapping['geonode_id'].apply(lambda x: find_location(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec55d68c-e9ca-472d-ba15-b22bcf00ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(merged_data,org_mapping,on=\"geonode_id\",how=\"left\")\n",
    "merged_data.to_excel(\"merged_data.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
